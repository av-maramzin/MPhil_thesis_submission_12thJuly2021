\chapter{Related Work}
\label{related_work}
\quad The topics of parallel computing, parallel software development, and software parallelization have a long and rich history. Historically parallel computers were programmed for doing various scientific simulations, particularly in the natural and engineering sciences. The limits of CPU frequency scaling and power consumption that came in 00' brought parallel computing to the area of desktop computers and general-purpose applications. Unfortunately, the legacy software did not adapt to these changes transparently and the field of software parallelization came to the spotlight.\newline\null
\quad Section \ref{related_work_autopar} describes automatic parallelization. Automatically parallelizing compilers are largely limited to embarrassingly parallel scientific C and Fortran codes. To exploit the potential of upcoming multi-cores, and various heterogeneous systems it will be necessary to extend the scope of automatic parallelization to a broader class of programs containing complex pointer-based code and finding coarse-grain parallelism. Compilers cannot make such decisions in general as they cannot infer the higher-level semantics of the program. Sections \ref{related_work_ml}, \ref{related_work_dcp}, \ref{related_work_as_and_pp} overview the research studying alternative parallelization strategies. Section \ref{related_work_ml} describes machine learning based methods. Due to the inherent statistical errors of these methods, the latter are relatively new to the area of software parallelization, where program correctness is paramount. The DCP problem has been introduced in Section \ref{background_dcp}. Section \ref{related_work_dcp} provides a literature review on the subject. Lastly, Section \ref{related_work_as_and_pp} provides some references to works addressing the automatic recognition of parallel algorithmic skeletons and higher-level parallelizing program transformations. These problems are very challenging and not solved yet. Higher-level methods work in a manual or semi-automatic way requiring a programmer to approve or manually conduct the proposed transformation.
\section{Automatic parallelization in compilers}
\label{related_work_autopar}
\quad There is a large body of work on automatic and semi-automatic parallelization of sequential legacy code \cite{6813266}, \cite{article12345}, \cite{Bacon:1994:CTH:197405.197406}, \cite{Kennedy:2001:OCM:502981}. Years have been spent building various compiler infrastructures for research on parallelizing \cite{Kennedy:2001:OCM:502981} and optimizing \cite{Muchnick:1998:ACD:286076} compilers, e.g., SUIF (Stanford University Intermediate Format) compiler \cite{546613},\cite{10.5555/891422},\cite{suif_compiler}, Polaris \cite{polaris}, \cite{10.1109/M-PDT.1994.329796} and LLVM (Low-Level Virtual Machine) \cite{llvm-compiler-infrastructure},\cite{Lattner:2004:LCF:977395.977673}. The industry has its own well-known and well-established parallelizing compilers like Intel C/C++ Compiler (ICC) \cite{icc-compiler} or GNU Compiler Collection (GCC) project \cite{gnu-compiler}.\newline\null
\quad It is well understood how to parallelize scientific C and Fortran code with perfectly nested loops that operate over flat arrays \cite{97902}, or even non-perfectly nested ones \cite{10.1145/263699.263719}. Furthermore, there are works on how to parallelize sequential loops across procedure boundaries \cite{10.1145/125826.126055},\cite{10.5555/645671.665383}, or with some prior enabling transformations like array privatization \cite{10.1145/158511.158515}. These works, however, focus on loops over arrays. Some research efforts deal with larger code structures
\cite{1299188}. Decoupled software pipelining is a compilation technique to automatically recognize and extract thread-level parallelism from program loops by splitting the instructions of those loops into multiple smaller loops (pipeline stages) that execute in independent threads, and inserting dependence communication where necessary between these threads so that they remain synchronized \cite{1540952}, \cite{10.1145/1400112.1400113}. Software pipelining might require code duplication and eventually lead to code bloat that, if it is too large, can increase pressure on the cache memory and affect execution speed via a decrease in cache performance. Nevertheless, for loops with large trip counts on architectures with enough instruction level parallelism, the technique easily performs well enough to be worth any increase in code size.\newline\null
\quad Despite all the research efforts automatic parallelization remains largely limited to sequential scientific codes, where DOALL type loops operate over flat arrays with boundaries known at compile-time. There is a range of reasons that complicate the applicability of automatic parallelization techniques to wider areas. Dependence analysis is hard for code that uses indirect addressing, pointers, recursion, or indirect function calls because it is difficult to detect such dependencies at compile time. Loops often have a statically unknown number of iterations. Access to global resources might create race conditions and are difficult to coordinate in terms of memory allocation, I/O, and shared variables. Irregular algorithms that use input-dependent indirection interfere with compile-time analysis and optimization. All enumerated complications are very typical to the real-world code. As we demonstrate in Section \ref{background_challenges_automatic} all above problems can even materialize on a relatively simple and highly parallel suite of NASA Parallel Benchmarks (NPB) \cite{nasa-parallel-benchmarks}.\newline\null
\quad Speculative multithreading or thread-level speculation (TLS) techniques provide a workaround research direction to tackle the limitations of static program analysis. TLS techniques enable parallel execution of sequential applications on a multiprocessor by extracting speculative threads from serial code and submitting them for execution in parallel. At all times, there is at least one safe thread. While speculative threads venture into unsafe program sections, the safe thread executes code non-speculatively. Such techniques speculate the non-existence of dependencies \cite{10.1145/291069.291020} and speculative threads run under some assumptions on the values of input data. Should these assumptions prove wrong, then the state of speculative thread should be discarded. TLS is aware of the order in which such program sections would run in a single-threaded execution. Usually in TLS systems threads are assigned numbers, where the lowest one corresponds to the safe thread. As threads execute, the hardware checks for cross-thread dependence violations. For example, if a thread reads a variable and, later on, another thread with a lower number writes it, a true dependence has been violated. In this case, the offending reader thread is squashed and restarted on the fly. As speculative threads execute, they buffer all their memory state updates into some intermediate structures. If a thread is squashed, the buffer is flushed and all its memory state updates are discarded. If instead, all the thread’s predecessors complete successfully, the thread becomes safe and it can commit its buffer into the main memory. If all assumptions prove to be correct the program can complete in a shorter time provided there were available hardware resources to schedule the threads efficiently.\newline\null
\quad TLS methods have their limitations. First, they require significant hardware support for handling thread contexts and detecting dependence violations in the memory subsystem \cite{10.1145/1122971.1122997},\cite{10.5555/822079.822712}. It is possible to implement these mechanisms in software, but then it might incur a significant amount of running time overhead, which would overwhelm any potential performance benefits from speculative-thread parallelism. Overall, speculative parallelization targets the inner program loops \cite{4147670}, \cite{10.1145/1150019.1136512}, \cite{10.1145/1122971.1122997} and cannot handle coarse-grain parallelism, especially if the loops contain I/O or other system calls \cite{10.1016/j.parco.2010.05.006}.\newline\null
\section{Machine learning in compilers}
\label{related_work_ml}
\quad Correctness is the most important property of the code. Although important, the running time or any other type of code performance characteristic is not always vitally critical. As all machine learning based techniques have always been characterized by their inherent and ineradicable errors \cite{James:2013:ISL:2517747}, the field of compilers has never been the primary target for these methods. Nonetheless, these techniques have found their application to some problems within the field.\newline\null
\textit{ML in Compiler Optimization.}
Usually, machine learning based methods target problems, where a misprediction will only lead to a hampered performance and not a functional failure. For example, machine learning based methods have been used for finding the most optimal compiler optimization parameters like predicting the optimal loop unroll factor \cite{4907653,1402082} or determining whether or not a function should be inlined \cite{Zhao2003ToIO,1559966}. These works are supervised classification problems and they target a fixed set of compiler options, by representing the optimization problem as a multi-class classification problem where each compiler option is a class. Recent works try to do scheduling and optimization of parallel programs for heterogeneous multi-cores. For example, Hayashi \emph{et al.}~\cite{Hayashi:2015:MPH:2807426.2807429} extracts various program features during compilation for use in a supervised learning prediction model aiming at the optimality of CPU vs. GPU selection. Evolutionary algorithms like generic search are often used to explore a large design space. Prior works~\cite{Almagor:2004:FEC:997163.997196,Cooper:2005:AAC:1065910.1065921,Ashouri:2017:MMC:3132652.3124452} have used evolutionary algorithms to solve the phase ordering problem (i.e.\ in which order a set of compiler transformations should be applied).\newline\null
\textit{Machine Learning and Parallelization.}
The application of machine learning based methods to the problem of software parallelization has not yet found a widespread practical utility. Mispredictions regarding the code parallelizability can lead to a broken dependency property and thus incorrect program execution. Nonetheless, there have already been works on predicting loop parallelizability, like the approach of Fried \emph{et al.}~\cite{fried_ea:2013:icmla}. Fried \emph{et al.} train a supervised learning algorithm on code hand-annotated with OpenMP parallelization directives to create a loop parallelizability predictor. These directives approximate the parallelization that might be produced by a human expert. Fried \emph{et al.}~focus on the comparative performance of different ML algorithms and studies the predictive performance that can be achieved on the problem and does not produce any practical application.\newline\null
\section{Discovery: data structure recognition}
\label{related_work_dcp}
\quad The idea of automatic discovery of higher-level entities in programs is not a new one. This discovery problem is closely interlinked and entangled with alias analysis techniques \cite{Muchnick:1998:ACD:286076} like points-to analysis \cite{Emami:1994:CIP:178243.178264}. The Points-to analysis is a variation of data flow analysis techniques. The final output is the sets of pairs of the form (\textit{p}, \textit{x}) (pointer variable \textit{p} points to a stack-allocated variable \textit{x}). These techniques are aimed at getting aliasing information regarding stack-allocated pointers.\newline\null
\quad The problem of understanding heap-directed pointers and heap-allocated linked data structures these pointers might point to is addressed with a family of static analysis techniques collectively known as shape analysis. Shape analysis techniques can be used to verify properties of dynamically allocated data structures in compile time. These are among the oldest and most well-known techniques. Three-valued logic \cite{Sagiv:1999:PSA:292540.292552}\cite{Wilhelm:2000:SA:647476.760384} can be used as an example. The technique proposes the construction of a mathematical model consisting of logical predicate expressions. The latter correspond to certain pointer operating imperative language program statements. An abstract interpretation of these statements leads to the construction of sets of shape graphs at various program points. Shape graphs approximate the possible states of heap-allocated linked data structures and answer the questions such as node reachability, data structure disjointness, cyclicity, etc. The major limitation of these simplified mathematical models is the lack of precision high level of abstraction leads to. The problem of precise shape analysis is provably undecidable.\newline\null
\quad The work of \cite{Ghiya:1996:TDC:237721.237724} proposes a simplified and hence more practical implementation of shape analysis. Authors propose to use direction \textit{D} and interference \textit{I} matrices instead of complex mathematical models to derive shape information on heap-allocated data structures. The entry of direction matrix \textit{D[p,q]} says if there exists a path from a node referred to by \textit{p} to a node referred to by q. In other words, if we can enter a path within the data structure through \textit{p} and exit through \textit{q}. The entry of interference matrix \textit{I[p,q]} says if the paths started from \textit{p} and \textit{q} are going to intersect at some point. Authors implement their technique withing McCAT compiler, which uses SIMPLE intermediate representation with a total of 8 statements (\textit{malloc()}, pointer assignments \textit{p=q}, structure updates \textit{p-$>$next=q}), which are capable of changing \textit{D} and \textit{I} matrices. Statements generate and kill entries in matrices. Moreover, they are capable of changing \textit{Shape} attributes of pointers. The technique has been assessed on various benchmarks (bintree, xref, chomp, assembler, loader, sparse, etc.) from the era before the standard benchmark suites became available. The technique mostly reported shapes as \textit{Trees} (be it a binary tree or a linked-list) or sometimes as \textit{DAGs} or \textit{Cycles} but with higher error rates in these last cases. The latter shows that the technique is imprecise and conservative.\newline\null
\quad One of the more recent techniques designed and developed by Ginsbach et al. is based on the pattern matching on LLVM IR level. The main idea is to specify computational idioms to be recognized in a domain-specific constraint-based programming language CAnDL \cite{Ginsbach:2018:CDS:3178372.3179515}. Constraints are specified over LLVM IR entities such as instructions, basic blocks, functions, etc. The CAnDL language allows rapid prototyping of new compiler optimizations based on pattern recognition and its substitution with optimized versions of matched idioms. The language and its relatively fast backtracking constraint solver are capable of recognizing not only simple arithmetic idioms (thus performing different peephole optimizations), but more complex computations like general reductions and histograms \cite{Ginsbach:2017:DEG:3049832.3049862}, vector products in graphics shaders \cite{Ginsbach:2018:AML:3296957.3173182}, sparse and dense linear algebra computations and stencils \cite{Ginsbach:2018:AML:3296957.3173182}. Having recognized these computational idioms the work \cite{Ginsbach:2018:AML:3296957.3173182} replaces them with a code for various heterogeneous APIs (MKL, libSPMV, Halide, clBLAS, CLBlast, Lift) and compares the resulting performance demonstrating an improvement over sequential versions and matching performance to hand-written parallel versions. The technique has been deployed on the sequential C versions of SNU NPB, the C versions of Parboil, and the OpenMP C/C++ versions of Rodinia demonstrating improved detection capabilities over the state-of-the-art techniques.\newline\null
\quad The other principally different technique has been recently proposed by Changhee Jung and Nathan Clark \cite{1669122}. The authors developed a Data-structure Detection Tool (DDT) based on the LLVM framework. The tool instruments load, store, and call instructions within program binaries and gathers dynamic traces for sample inputs. The traces are used to recreate a memory allocation graph for program data structures. Call graphs are used to identify interface functions interacting with the built memory graph. DDT traces memory graph properties (number of nodes, edges, etc.) before and after interface function calls into another Daikon tool to compute dynamic invariants (the number of nodes in a memory graph decreases by 1 after every \textit(delete()) interface method call, etc.). In the end, manually constructed decision tree is used to probabilistically match observed behavioral patterns against known data structure invariant properties. The technique has been deployed to recognize data structure implementations within standard libraries like STL, Apache (STDCXX), Borland (STLport), GLib, Trimaran achieving almost perfect recognition accuracy. Moreover, the technique has been able to recognize linked lists in Em3d and Bh Olden benchmarks, along with red-black trees implementing vectors in the Xalancbmk benchmark.\newline\null
\quad There has recently been other published works on the application of dynamic techniques to the problem of dynamic data structure recognition \cite{Rupprecht:2017:DID:3155562.3155607}\cite{Haller:2016:SDS:2938006.2938029}. The technique used in the DDT tool \cite{1669122} makes an assumption, that all modifications and interactions with memory graphs representing data structures happen through a set of interface functions. That is not true when we deal with aggressively optimizing compilers, which may eliminate some code or inline some functions. The MemPick tool \cite{Haller:2016:SDS:2938006.2938029} searches data structures directly on a built dynamic memory graph by analyzing its shape. The graph is built with the help of the Intel Pin binary instrumentation tool during quiescent periods when pointer operations are absent. DSIbin tool \cite{Rupprecht:2017:DID:3155562.3155607} operates with the source code rather than program binaries. Instead of memory points-to graphs, it uses strands as primitives, which abstract such entities as singly-linked lists.\newline\null
\quad The work of Dekker \cite{Dekker:1994:ADS:3107859.3107876} addresses the software design recovery problem in a completely different way. Contrary to the approaches described above, which operate on the IR and dynamic instruction stream levels, the work of Dekker operates at the level of an abstract syntax tree. Dekker's tool tries to compact the tree down to recognizable syntactic patterns by transforming it under a special grammar.
\section{Discovery: algorithmic skeletons and parallelism patterns}
\label{related_work_as_and_pp}
\quad Parallelizing sequential applications is a challenging and labor-intensive task, which requires a programmer to possess deep expertise in various fields. Parallelization can be done in numerous ways, due to many different ways in which an application can be parallelized and a large number of various programming models that can be used. The concept of algorithmic skeletons (parallelism patterns) (see Section \ref{background_skeletons}) has been proposed to alleviate the challenging task and provide a programmer with a portable human-friendly model of parallel computations. There is a vast array of various frameworks and libraries that implement the concept. They vary by the programming language they target, distribution library used to implement parallel/distributed computations internally (like MPI \cite{mpi}, OpenMP \cite{openmp_specs}, etc.), the sets of supported skeletons, and the allowed level and way of skeleton nesting, i.e composing more complex patterns of the basic ones; these include: RPL \cite{7445342}; FastFlow \cite{fastflow}; Microsoft’s Pattern Parallel Library \cite{microsoft-ppl}; and Intel’s Threading Building Blocks (TBB) library \cite{intel-tbb}.\newline\null
\quad Although, the libraries of parallelism patterns alleviate the process of parallel software development, their use still requires a manual effort. Before using a particular library, a programmer has to invest time and effort into learning its target use and limitations. Furthermore, discovering places in sequential code where parallel patterns might be introduced is
still highly non-trivial, often requiring expert manual analysis and profiling. There is a number of works addressing the task of automatic discovery of parallel patterns.\newline\null
\quad The work \cite{skeletons-static} proposes a static approach and develops Parallel Pattern Analyzer Tool (PPAT) capable of analyzing sequential C++ code statically to detect parallel patterns. The tool takes advantage of Clang library to generate an Abstract Syntax Tree (AST). It walks through the AST finding loop candidates to be analyzed for possible parallel patterns. For every loop, the tool checks a set of constraints specific to every target pattern. For example, for a loop to be a parallel pipeline, it must not write any global variables, pass no feedback between separate loop body stages, and there must be at least two stages to split the loop into. For farm pattern, the tool checks that the loop body has no RAW dependencies, no break statements, and writes no global variables. Authors evaluate the effectiveness and correctness of their approach using NAS \cite{nasa-parallel-benchmarks} and Rodinia benchmark suites by comparing automatically detected patterns against the manual analysis. The authors observe that the pattern detection quality of PPAT is close to that performed by a human expert. Authors parallelize detected patterns manually demonstrating final performance comparable to expertly parallelized benchmark versions. Therefore, reducing the human effort in transforming sequential codes into parallel.\newline\null
\quad Some works take advantage of functional languages. For instance, István Bozó et al. \cite{10.1145/2633448.2633453} develop a tool that detects parallel patterns in applications written in Erlang. Compared to other languages, Erlang
features make the detection process much simpler. Nonetheless, the tool requires profiling techniques to decide which pattern suits best a concrete problem.\newline\null
\quad The work \cite{roberto-lozano-skeletons} aims to highlight to a programmer code fragments, which could be replaced by calls to known parallel pattern library abstractions of map, reduce and their compositions in a legacy Pthreaded C/C++ code. The underlying technique is based on the analysis of dynamic data flow graphs (DDFGs) obtained during the execution of programs and thus is language-agnostic. The analysis uses constraint-based pattern matching to identify constrained DDFG subgraphs characteristic to the well-established parallel patterns while employing heuristics that trade analysis time against completeness making the approach scalable. The tool and methodology demonstrate excellent effectiveness and accuracy on Starbench benchmarks by finding 36 out of the expected 42 instances of parallel patterns with a high accuracy (reporting actual patterns in 98\% of the cases). Authors re-express the found patterns via a parallel pattern library, making code freely portable across CPU/GPU systems and performing competitively with hand-tuned implementations at zero additional effort.\newline\null
\quad There are also hybrid methods of parallel pattern discovery. The work \cite{9092377} employs both static and dynamic trace-based analysis, together with hotspot detection. First, using running time profiling the methodology obtains a list of hotspot loop candidates, which pass through static analysis, leveraging the existing Pattern Analyzer Tool PPAT \cite{skeletons-static}. Independently from the static analysis, candidate loops are also passed through a new dynamic trace-based pattern detection mechanism. Finally, the user checks manually that the candidate detected patterns (from either analysis) are indeed applicable. The mechanism is evaluated on a number of representative benchmarks, demonstrating good accuracy, precision, and recall scores for map and reduce algorithmic skeletons. The scores are compared against the manual analysis.\newline\null
\quad As the sequential code gives the cleanest starting point for the introduction of parallel patterns, the work \cite{standrewsposix} studies how parallel legacy C/C++ pthreaded codes could be converted back to sequential version and ultimately restored to a modern parallel pattern based equivalent form. This work studies the specifics of parallel legacy pthreaded codes and proposes a novel methodology to accomplish the task. The restoration is conducted through a systematic application of a number of identified program transformations. Authors design and define a set of restorative transformations common to many legacy pthreaded codes. These transformations aim to (i) eliminate Pthread operations from legacy C/C++ programs; (ii) perform code repair, fixing any bugs introduced in (i); and, (iii) reshape code in preparation for parallel pattern introduction. The work targets only farm and pipeline patterns. The transformations presented in the work are intended as manual transformations. The implementation of these refactorings into a semi-automatic tool is envisaged as future work. Authors use the Intel TBB library to evaluate these transformations on a set of benchmarks and demonstrate that the removal of parallelism allows to manually derive structured parallel code that is comparable to the original legacy-parallel version in terms of performance while being more portable, adaptive, and maintainable. Additionally, authors record improvements in terms of cyclomatic complexity \cite{1702388} and Lines Of Code (LOC) metric.

